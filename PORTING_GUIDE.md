# AI Model Porting Notes

This guide summarizes where the current demo performs AI processing and what to touch when replacing the `Model` contents with files from `我要换的Model`.

## Key pipeline touch points
- **Inference scheduling and buffers**: `Appli/Core/Src/app.c` sets up NN input/output queues, launches the NN thread, and calls the autogenerated network runner `LL_ATON_RT_Main` using buffers registered through `LL_ATON_Set_User_Input_Buffer_Default` / `LL_ATON_Set_User_Output_Buffer_Default` (see lines 81-168).
- **Post-processing selection**: `Appli/Core/Inc/app_config.h` chooses YOLOv2 post-processing via `POSTPROCESS_TYPE` and defines input/output tensor sizes and class table (lines 27-54). `Appli/Core/Inc/postprocess_conf.h` provides the YOLOv2 anchor grid and class count (lines 16-30).
- **Post-processing implementation**: `Appli/Core/Src/app_postprocess.c` instantiates the per-model parameters and routes the raw network output through the correct post-processing kernel based on `POSTPROCESS_TYPE` (lines 24-318). The YOLOv2 path currently expects a single float output tensor.
- **Autogenerated network code**: `Model/network.c` exposes the user I/O setters/getters and embeds the graph/epoch controller that `LL_ATON_RT_Main` executes (lines 74-233). Buffer size checks in this file need to match your new model’s input/output requirements.

## When swapping in files from `我要换的Model`
1. Replace the `Model/` artifacts with the new ones, ensuring `network.c`, `network_ecblobs.h`, pools, and weight blobs are updated together.
2. Update `app_config.h` with the new input resolution, pixel format, output buffer size, number of classes, and post-processing type expected by your model.
3. Adjust `postprocess_conf.h` (anchors, grid sizes, class count, thresholds) to match the model’s output layout.
4. If the new model output shape or quantization differs (e.g., YOLOv5 variant with `float32[1,10647,14]`), select or implement the corresponding post-processing branch in `app_postprocess.c` and ensure `NN_BUFFER_OUT_SIZE` matches the raw tensor size.
5. Confirm `LL_ATON_Set_User_Output_Buffer_Default` checks in `Model/network.c` match the updated output size to avoid runtime alignment/size errors.

## Bringing Python-side logic to C
- Convert any custom Python pre/post-processing to C by mirroring tensor reshapes, scaling, and decoding inside `app_postprocess.c` (add a new branch keyed by a custom `POSTPROCESS_TYPE`).
- Place reusable headers in `Appli/Core/Inc/` and implementations in `Appli/Core/Src/` so they integrate with the existing build and thread structure.
- Keep inference entry points unchanged (`LL_ATON_RT_Main` in `app.c`) to reuse buffer management and threading.
